{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install dependencies and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m5 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install e2b-code-interpreter python-dotenv ollama docker agentrun\n",
    "import time\n",
    "import base64\n",
    "import docker\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from e2b_code_interpreter import Sandbox\n",
    "from agentrun import AgentRun\n",
    "import ollama\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"E2B_API_KEY\"), \"E2B_API_KEY is not set in the .env file\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build and run container (AgentRun only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import io\n",
    "\n",
    "f = io.StringIO()\n",
    "with contextlib.redirect_stdout(f): # supress stdout\n",
    "    ! docker-compose -f agentrun_docker/docker-compose.yml up -d --build \n",
    "    load_dotenv(\"./agentrun_docker/.env.dev\")\n",
    "    CONTAINER_NAME = os.getenv(\"CONTAINER_NAME\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Instantiate runtimes\n",
    "For AgentRun, we have to make sure that the container is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbx_e2b = Sandbox()\n",
    "sbx_agentrun = AgentRun(container_name=CONTAINER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Copy dataset to runtimes\n",
    "E2B provides a built-in function to do so. For AgentRun, we have to do it manually by copying the dataset to our running container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"dataset.csv\", \"rb\") as f:\n",
    "    \n",
    "    # For E2B, we can use the built-in function\n",
    "    sbx_e2b.files.write(\"/code/dataset.csv\", f)\n",
    "\n",
    "    # For AgentRun, we have to do it manually by copying the dataset to our running container\n",
    "    client = docker.from_env()\n",
    "    container = client.containers.get(CONTAINER_NAME)\n",
    "    container.put_archive(\"/code/\", f.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Set the user's prompt\n",
    "\n",
    "We will ask a question about the data. The first part of the prompt could also be part of the system prompt, but we will put it here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "user_message = \"\"\"\n",
    "You are a data scientist and expert Python programmer.\n",
    "You will be asked questions about a dataset and will use Python code to analyze the data to answer these questions.\n",
    "You have access to a Python environment and can use the run_python_code tool to execute code in this environment.\n",
    "The dataset you will work with is provided as a file named \"/code/dataset.csv.\"\n",
    "Use only pandas.\n",
    "\n",
    "Question:\n",
    "What is the city with the highest average salary in the provided dataset and what is such salary?\n",
    "\"\"\"\n",
    "messages.append({\n",
    "        'role': 'user', \n",
    "        'content': user_message\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Query the model\n",
    "We will use llama 3.2, a 8B model with pretty decent scores in tool use given its size. I can ru it on my laptop ðŸ™ƒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    tools=[{\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'run_python_code',\n",
    "        'description': 'Run python code and scripts to answer data science questions',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'code': {\n",
    "              'type': 'string',\n",
    "              'description': 'The python code to be executed',\n",
    "            },\n",
    "          },\n",
    "          'required': ['code'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "  ],\n",
    "  options={\n",
    "    'temperature': 0.0,\n",
    "  }\n",
    ")\n",
    "messages.append(response['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Define the execution functions\n",
    "We will define a single function `run_ai_generated_code` that supports executing the E2B or the AgentRun runtime. Additionally, we defined `process_output_e2b` and `process_output_agentrun` since both frameworks handle output data differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output_e2b(execution_output):\n",
    "    if execution_output.error:\n",
    "        return execution_output.error\n",
    "    \n",
    "    results_idx = 0\n",
    "    for result in execution_output.results:\n",
    "        if result.png:\n",
    "            with open(f'result-{results_idx}.png', 'wb') as f:\n",
    "                f.write(base64.b64decode(result.png))\n",
    "                print(f'Saved result-{results_idx}.png')\n",
    "        else:\n",
    "            print(f'Result {results_idx}:')\n",
    "            print(result)\n",
    "        results_idx += 1\n",
    "    return  execution_output.logs.stdout[0]\n",
    "\n",
    "def process_output_agentrun(execution_output):\n",
    "    # AgentRun does not return any fancy output, just the stdout\n",
    "    return execution_output\n",
    "\n",
    "def run_ai_generated_code(\n",
    "                        ai_generated_code: str,\n",
    "                        sbx_runtime: Sandbox | AgentRun,\n",
    "                        ):\n",
    "    if isinstance(sbx_runtime, Sandbox):\n",
    "        runner_function = sbx_runtime.run_code\n",
    "    elif isinstance(sbx_runtime, AgentRun):\n",
    "        runner_function = sbx_runtime.execute_code_in_container\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid runtime: {sbx_runtime}\")\n",
    "\n",
    "    execution = runner_function(ai_generated_code)\n",
    "    process_output_function = process_output_e2b if isinstance(sbx_runtime, Sandbox) else process_output_agentrun\n",
    "    \n",
    "    return process_output_function(execution)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Process the LLM's response \n",
    "Execute code in the E2B and AgentRun runtimes, according to the tool usage defined by the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated code:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "# Load the dataset\n",
      "df = pd.read_csv(\"/code/dataset.csv\")\n",
      "# Group by city and calculate average salary\n",
      "avg_salary_by_city = df.groupby(\"city\")['salary'].mean()\n",
      "# Get the city with the highest average salary and its value\n",
      "highest_avg_salary_city = avg_salary_by_city.idxmax()\n",
      "highest_avg_salary = avg_salary_by_city.max()\n",
      "print(f\"The city with the highest average salary is {highest_avg_salary_city} with an average salary of {highest_avg_salary}\")\n",
      "====================================================================================================\n",
      "Executing code in the e2b sandbox....\n",
      "Code execution finished!\n",
      "Response from the function:\n",
      "The city with the highest average salary is Seattle with an average salary of 73500.0\n",
      "\n",
      "Elapsed time: 0.34 seconds\n",
      "====================================================================================================\n",
      "Executing code in the agentrun sandbox....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scastanoc/Library/CloudStorage/Dropbox/work/blog/e2b-codeinterpreter-envs/agent-runtime/.venv/lib/python3.12/site-packages/RestrictedPython/compile.py:206: SyntaxWarning: Line None: Prints, but never reads 'printed' variable.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code execution finished!\n",
      "Response from the function:\n",
      "The city with the highest average salary is Seattle with an average salary of 73500.0\n",
      "\n",
      "Elapsed time: 1.90 seconds\n"
     ]
    }
   ],
   "source": [
    "messages_e2b = messages.copy()\n",
    "messages_agentrun = messages.copy()\n",
    "if response['message'].get('tool_calls'):\n",
    "    available_functions = {\n",
    "        'run_python_code': run_ai_generated_code,\n",
    "    }\n",
    "    for tool in response['message']['tool_calls']:\n",
    "        arguments = tool['function']['arguments']\n",
    "        code = arguments['code']\n",
    "        print('Generated code:')\n",
    "        print(code)\n",
    "        \n",
    "        for runtime_name in [\"e2b\",\"agentrun\"]:\n",
    "            start_time = time.time()\n",
    "            print(''.join(['='] * 100))\n",
    "            print(f'Executing code in the {runtime_name} sandbox....')\n",
    "            runtime = sbx_e2b if runtime_name == \"e2b\" else sbx_agentrun\n",
    "            function_to_call = available_functions[tool['function']['name']]\n",
    "            function_response = function_to_call(code, runtime)\n",
    "            print('Code execution finished!')\n",
    "            print('Response from the function:')\n",
    "            print(function_response)\n",
    "            end_time = time.time()\n",
    "            print(f'Elapsed time: {end_time - start_time:.2f} seconds')\n",
    "            if runtime_name == \"e2b\":       \n",
    "                messages_e2b.append({\n",
    "                    'role': 'tool',\n",
    "                    'content': function_response\n",
    "                })\n",
    "            elif runtime_name == \"agentrun\":\n",
    "                messages_agentrun.append({\n",
    "                    'role': 'tool',\n",
    "                    'content': function_response\n",
    "                })\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid runtime name: {runtime_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
